{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-18-239.us-west-2.compute.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ip = 54.186.189.193\n",
      "\n",
      "root\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- cool: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- funny: integer (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- stars: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- useful: integer (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ip = \"54.186.189.193\"\n",
    "city = \"Las Vegas\"\n",
    "format_string = \"com.mongodb.spark.sql.DefaultSource\"\n",
    "\n",
    "business = spark.read.format(format_string).option(\"uri\",\"mongodb://{}/yelp.business\".format(ip)).load()\n",
    "review = spark.read.format(format_string).option(\"uri\",\"mongodb://{}/yelp.review\".format(ip)).load()\n",
    "\n",
    "print \"ip = %s\" % ip\n",
    "print \"\"\n",
    "review.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      city|count|\n",
      "+----------+-----+\n",
      "| Las Vegas|24768|\n",
      "|   Phoenix|15656|\n",
      "|   Toronto|15483|\n",
      "| Charlotte| 7557|\n",
      "|Scottsdale| 7510|\n",
      "|Pittsburgh| 5688|\n",
      "|  Montr√©al| 5175|\n",
      "|      Mesa| 5146|\n",
      "| Henderson| 4130|\n",
      "|     Tempe| 3949|\n",
      "+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "business.groupby('city').count().orderBy('count', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u\"What can I say.. Wowzers! Probably one of the best steak houses I've been too. Service was absolutely flawless and dinner was excellent . Ordered seafood tower, wedge, wagyu filet, chateaubriand, bacon grits and saut\\xe9ed  mushrooms Will definitely be back!\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = review.select('business_id', 'text')\n",
    "ids = business.filter(business.city == city).select('business_id')\n",
    "joined = ids.join(review, 'business_id', 'inner')\n",
    "train_raw = joined.rdd.map(lambda x: x[1]).cache()\n",
    "train_raw.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108512"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_raw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = sc.parallelize(open(\"./stop_words\",\"r\").readlines()).map(lambda x: x.strip()).collect()\n",
    "common_words = ['place','time','times','food','things','customer','service','people','staff','area','order',\\\n",
    "                'year','years','day','days','minutes','company','city','customers','price','prices','money',\\\n",
    "                'location','hour','hours',\"don't\",\"doesn't\",\"didn't\",\"won't\"]\n",
    "accepted_pos = ['NN','NNP','NNS']#,'JJ','JJR','JJS']\n",
    "\n",
    "def tokenize(text):\n",
    "    regex = re.compile('[' + re.escape('!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~') + '0-9\\\\r\\\\t\\\\n]')\n",
    "    words = nltk.word_tokenize(regex.sub(\" \", text.lower()))\n",
    "    words = [w for w in words if len(w) > 2 and w not in stop_words and w not in common_words]\n",
    "    unigrams = [word for word,pos in nltk.pos_tag(words) if pos in accepted_pos]\n",
    "    return unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                  _1|            features|\n",
      "+--------------------+--------------------+\n",
      "|[wowzers, steak, ...|(2000,[12,65,155,...|\n",
      "|[hopes, delmonico...|(2000,[3,4,12,20,...|\n",
      "|[guys, weekend, a...|(2000,[65,97,122,...|\n",
      "|[stars, bump, thi...|(2000,[3,7,14,16,...|\n",
      "|[herb, butter, st...|(2000,[2,35,109,1...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# list_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "word_occurence = train_raw.map(lambda x: [tokenize(x)])\n",
    "word_occurence = word_occurence.toDF()\n",
    "\n",
    "cv = CountVectorizer(inputCol='_1', outputCol='features', vocabSize=2000)\n",
    "cv_model = cv.fit(word_occurence)\n",
    "train = cv_model.transform(word_occurence).cache()\n",
    "\n",
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_model = LDA(k=15, maxIter=10).fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------+\n",
      "|topics_words                                                                       |\n",
      "+-----------------------------------------------------------------------------------+\n",
      "|[buffet, lunch, quality, dinner, crab, restaurant, meat, chef, rib, eat]           |\n",
      "|[cream, ice, vegas, chocolate, tea, love, bar, buffet, flavors, experience]        |\n",
      "|[sushi, pork, rolls, rice, spicy, roll, vegas, soup, beef, dishes]                 |\n",
      "|[breakfast, eggs, massage, vegas, coffee, pancakes, toast, ramen, menu, eat]       |\n",
      "|[room, hotel, rooms, pool, vegas, night, stay, casino, strip, check]               |\n",
      "|[restaurant, steak, waiter, experience, meal, vegas, dinner, night, lobster, filet]|\n",
      "|[fries, burger, burgers, sandwich, beer, coffee, sandwiches, bar, meat, beef]      |\n",
      "|[car, work, job, experience, phone, office, business, store, call, manager]        |\n",
      "|[hair, vegas, las, hotel, night, cut, salon, cake, experience, job]                |\n",
      "|[bar, drinks, kids, vegas, fun, experience, games, owner, drink, family]           |\n",
      "|[strip, casino, night, beer, vegas, pool, view, restaurant, options, bar]          |\n",
      "|[chicken, pizza, rice, restaurant, sauce, thai, meal, salad, menu, dinner]         |\n",
      "|[manager, dinner, wait, restaurant, night, items, experience, friends, room, group]|\n",
      "|[night, music, vegas, club, fun, drinks, dance, girls, experience, lot]            |\n",
      "|[vegas, menu, burger, dog, fries, dogs, wine, stars, restaurant, pasta]            |\n",
      "+-----------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def indices_to_terms(vocabulary):\n",
    "    def indices_to_terms(xs):\n",
    "        return [vocabulary[int(x)] for x in xs]\n",
    "    return udf(indices_to_terms, ArrayType(StringType()))\n",
    "\n",
    "# Describe topics.\n",
    "topics = lda_model.describeTopics(10)\n",
    "topics.withColumn(\"topics_words\", \\\n",
    "                  indices_to_terms(cv_model.vocabulary)(\"termIndices\")).select('topics_words').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
